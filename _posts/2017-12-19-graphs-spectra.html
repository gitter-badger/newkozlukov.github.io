---
title: "Overview of graph spectra stuff"
categories: math
layout: slides
slides_theme: white
excerpt: |
  A part of my talk on current-problems-2017
  dedicated to the graph spectra applications
---

<section>
    <h3>Structure</h3>

    <ul>
        <li>Which graphs exactly?</li>
        <li>Which spectra?</li>
        <li>Why?</li>
    </ul>
</section>
<section>
    <h3>Which graphs?</h3>
    <p>
    A "graph" hereafter is a simple directed graph
    with the finite set of vertices $V=\left\{1,\ldots,N\right\}$
    and the set of directed edges $E \subset V^2$.
    </p>
</section>
<section>
    <h3>Adjacency matrices</h3>
    <p>
    Such a graph is uniquely defined by its <i>adjacency matrix</i>
    $$A = (a_{ij}),\ i,j{=}\overline{1,N},$$
    where $a_{ij}$
    is the number of directed edges
    from vertex $j$ to vertex $i$.<br/>
    Note the inversion of indices.
    </p>
</section>
<section>
    <h3>Simple graphs</h3>
    <p>
    Sometimes we'll restrict ourselves to <i>simple graphs</i>:
    the ones without loops and multiple edges.
    In terms of adjacency matrix:
    $$a_{ij}\in \{0,1\},\ a_{ii} = 0,$$
    for $i,j = \overline{1,N}.$
    </p>
</section>
<section>
    <h3>Which spectra?</h3>

    <p>
    We are interested in
    </p>
    <ul>
        <li>the spectrum of the adjacency matrix $A$</li>
        <li>and the spectra of transition matrices of some random processes.</li>
    </ul>
</section>
<section>
    <h3>The (Bonacich) eigenvector centrality</h3>

    <p>Consider a problem of ranking
    scientific papers or web-pages
    that reference each other.</p>
    <ol>
        <li>The more links to a page the greater importance.</li>
        <li class="fragment">The more important referrers the greater importance.</li>
        <li class="fragment">Iterate.</li>
        <li class="fragment">$$x_j = c \sum_i a_{ik} x_k.$$</li>
    </ol>
</section>
<section>
    <p>In more convenient form:
    $$A x = \lambda x.$$</p>
    <p class="fragment">
    For the importances to be non-negative
    a principal eigenvector is chosen.<br/>
    That is one corresponding to the largest (the Perron-Frobenius) eigenvalue.</p>
    <p class="fragment">For a strongly-connected simple graph
    the adjacency matrix is always irreducible and Perron-Frobenius applies.</p>
</section>
<section>
    <h3>Google's PageRank: random surfer interpretation</h3>

    <p>An alternative approach to define eigenvector centrality.
    Consider an agent visiting a web page
    and then randomly following one of the links.</p>
    <p class="fragment">It's a Markovian random walk with the probability
    of transition from state (web-page) $j$
    to state $i$ equal to $$p_{ij} = \frac{a_{ij}}{D_j}.$$
    Here $D_j = \sum_k a_{kj}$ is the out-degree of the node $j$.</p>
</section>
<section>
    <h3>Random surfer interpretation</h3>

    <p>
    Let $D=\mathrm{diag}(d_1,\ldots d_N)$.</p>
    <p class="fragment">
    Then $P=AD^{-1}$ is the (column-stochastic)
    transition matrix of this process.</p>
    <p class="fragment">
    Its Perron-Frobenius eigenvalue is $1$.
    It has a non-negative eigenvector
    that defines a stationary distribution:
    $$x = P x,$$
    $x\geq 0,\ \sum_j x_j = 1$.
    </p>
</section>
<section>
    Interpretation:
    the fraction of time a random surfer would spend in each node</p>
</section>
<section>
    <h3>The second eigenvalue of $P$</h3>

    <p>Customarily the eigenvector centrality is computed
    using the power iteration method.
    For a <b>positive</b> transition matrix $P$ (Perron-Frobenius):
    <ol>
        <li>Start at arbitrary $x^{(0)}\neq 0$.</li>
        <li>Set
            $x^{(n)} = \frac{1}{\|x^{(n-1)}\|} P x^{(n-1)},\ n\in\mathbb{N}.$
        </li>
    </ol>
    </p>
    <p>
    The process converges to a strictly positive eigenvector $x$
    which corresponds to the eigenvalue $1$.
    This eigenvalue is simple and equals the spectral radius of $P$.
    </p>
</section>
<section>
    <h3>The second eigenvalue of $P$</h3>

    <p>
    First, it is obvious that for positive $P$:
    $$\|x - x^{(n)}\| = O(\lvert\frac{\lambda_2}{\lambda_1}\rvert^n) = O(\lvert\lambda_2\rvert^n),$$
    where $\lambda_2$ is the second-largest eigenvalue of $P$.<br/>
    In other words the speed of convergence is determined by $\lambda_2$.</p>
    <p class="fragment">
    Meyer (1994) also shows that (for non-negative $P$)
    the sensitivity of stationary distributions
    to perturbations in P
    is determined by the gap
    between the two largest eigenvalues.
    </p>
</section>
<section>
    <h3>Convex combinations</h3>

    <p>The Page's paper also deals with the disconnectedness of the graph of web.
    It is done by allowing an agent (a random surfer)
    to reset and jump to an arbitrary page
    with some probability $\alpha$.
    </p>
    <p class="fragment">
    The transition matrix for this new process is:
    $$\mathcal{H} = (1-\alpha)P + \alpha J,$$
    where $J$ is the all-ones matrix.
    </p>
    <p class="fragment">
    This matrix is positive and thus the Perron-Frobenius theorem
    and the power method are applicable!
    </p>
</section>
<section>
    <h3>Viral spread.</h3>

    <p>
    The Susceptible-Infective-Susceptible model
    describes viral spread in a network on $N$ nodes
    as a Markov process with $2^N$ states.
    Specifically, state is a vector of nodes' statuses
    (each node is either infected or susceptible to infection).<br/>
    </p>
</section>
<section>
    <h3>Viral spread.</h3>

    <p>
    Wang et al. investigated ergodicity of such a system
    in the following case:
    </p>
    <ul>
        <li>An infected node gets cured with the probability $\delta$.</li>
        <li>A healthy neighbour of infective node gets infected w.p. $\beta$.</li>
    </ul>
</section>
<section>
    <h3>Viral spread.</h3>

    <p>
    Turns out (Wang et. al):
    $$\mathrm{Pr}\left\{\text{node}\ i\ \text{is infected at the step}\ n\right\} \to 0,\ \text{as}\ n\to\infty,$$
    for all $i$
    if (and only if) $$\frac{\beta}{\delta} < \frac{1}{\mathrm{spr}A}.$$
    Moreover this probability decays in exponential manner.
    </p>
    <p>
    Otherwise infection lingers for ever.
    </p>
</section>
<section>
    <h3>Viral spread.</h3>
    <p>
    TLDR: the spectral radius of the adjacency matrix
    represents the level of inter-connectedness of a network.
    </p>
</section>
<!-- TODO
    -   Spectral clustering, NNMF
    -   Almost-invariant sets
-->
<section>
        <h3>Kronecker products</h3>

        <p>
        One of the most general operations on graphs
        <i>is the non-complete extended p-sum</i> (NEPS) is defined as follows (see Cvetkovic):
        </p>
        <p class="fragment">
        The NEPS of graphs $G_1,\ldots, G_n$
        with basis $\mathcal{B}\subset \{0,1\}^n\setminus 0$
        is the graph with vertex set $V(G_1)\times\cdots\times V(G_n)$,
        in which a vertex $u=(u_1,\ldots,u_n)$ is linked to a vertex $v=(v_1,\ldots,v_n)$
        IFF there is $\beta=(\beta_1,\ldots,\beta_n)\in\mathcal{B}$
        such that
        $u_i=v_i$ whenever $\beta_i=0$
        and $u_i$ is linked to $v_i$ in $G_i$ whenever $\beta_i=1$.
        </p>
</section>
<section>
    <h3>Kronecker products</h3>
    
    <p>
    NEPS can serve a basis for some other important operations.
    </p>
    <ul>
        <li>The cartesian product of two graphs: $\mathcal{B}=\{(0,1),\ (1,0)\}$.</li>
        <li>The strong product: $\mathcal{B}=\{ (0,1),\ (1, 0),\ (1,1) \}$.</li>
        <li>etc.</li>
    </ul>
</section>
<section>
    <h3>Kronecker products</h3>

    <p>
    The adjacency matrix of the NEPS of $G_1,\ldots,G_n$
    with basis $\mathcal{B}$ is
    $$A = \sum_{\beta\in\mathcal{B}} A_1^{\beta_1} \otimes\cdots\otimes A_n^{\beta_n}$$
    where $A_1,\ldots,A_n$ are adjacency matrices of $G_1,\ldots, G_n$ resp.
    and $\otimes$ denotes the Kronecker product (see below).
    </p>
</section>
<section>
    <h3>Kronecker products</h3>

    <p>
    The Kronecker product of two matrices $A=(a_{ij})\in\mathbb{C}^{m{\times}n}$
    and $B=(b_{ij})\in\mathbb{C}^{p{\times}q}$ is the matrix of the size $mn{\times}pq$
    defined as:
    $$A{\otimes}B =
    \begin{pmatrix}
    a_{11} B & \cdots & a_{1n} B \\
    \vdots & \ddots & \vdots \\
    a_{m1} B & \cdots & a_{mn} B \\
    \end{pmatrix}.$$
    </p>
</section>
<section>
    <h3>Kronecker products</h3>

    <p>Kronecker product has some convenient properties:</p>
    <ul>
        <li> It is associative:
            $A\otimes (B\otimes C) = (A\otimes B)\otimes C.$</li>
        <li class="fragment"> It is distributive w.r.t. addition:
            $(A+B)\otimes(C+D) = A\otimes C + A\otimes D +$</br>$+ B\otimes C + B\otimes D.$</li>
        <li class="fragment">$(AB)\otimes(CD) = (A\otimes C)(B\otimes D)$
            whenever products \( AB \) and \( CD \) make sense.
            (I.e. it corresponds to tensor products of operators)
        </li">
        <li class="fragment">
            $\operatorname{tr}(A\otimes B) = \operatorname{tr}A\operatorname{tr}B$.</li>
        <li class="fragment"> $A$ and $B$ are symmetric $\implies$
            $A\otimes B$ is symmetric.</li>
    </ul>
</section>
